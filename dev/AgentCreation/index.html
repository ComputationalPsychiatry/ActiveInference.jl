<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Creating the Agent · ActiveInference.jl</title><meta name="title" content="Creating the Agent · ActiveInference.jl"/><meta property="og:title" content="Creating the Agent · ActiveInference.jl"/><meta property="twitter:title" content="Creating the Agent · ActiveInference.jl"/><meta name="description" content="Documentation for ActiveInference.jl."/><meta property="og:description" content="Documentation for ActiveInference.jl."/><meta property="twitter:description" content="Documentation for ActiveInference.jl."/><meta property="og:url" content="https://ilabcode.github.io/ActiveInference.jl/AgentCreation/"/><meta property="twitter:url" content="https://ilabcode.github.io/ActiveInference.jl/AgentCreation/"/><link rel="canonical" href="https://ilabcode.github.io/ActiveInference.jl/AgentCreation/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../Introduction/">ActiveInference.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><span class="tocitem">General Introduction</span><ul><li><a class="tocitem" href="../Introduction/">Introduction</a></li><li><a class="tocitem" href="../GenerativeModelCreation/">Creation of the Generative Model</a></li><li class="is-active"><a class="tocitem" href>Creating the Agent</a><ul class="internal"><li><a class="tocitem" href="#Initilising-the-Agent"><span>Initilising the Agent</span></a></li><li><a class="tocitem" href="#Initialising-the-Agent-with-Learning"><span>Initialising the Agent with Learning</span></a></li></ul></li><li><a class="tocitem" href="../Simulation/">Simulation</a></li><li><span class="tocitem">Model Fitting</span></li></ul></li><li><span class="tocitem">Usage Examples</span><ul><li><span class="tocitem">T-Maze Simulation</span></li><li><span class="tocitem">T-Maze Model Fitting</span></li></ul></li><li><span class="tocitem">Theory</span><ul><li><input class="collapse-toggle" id="menuitem-3-1" type="checkbox"/><label class="tocitem" for="menuitem-3-1"><span class="docs-label">Active Inference Theory</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><span class="tocitem">Perception</span></li><li><span class="tocitem">Action</span></li><li><span class="tocitem">Learning</span></li></ul></li><li><a class="tocitem" href="../GenerativeModelTheory/">POMDP Theory</a></li></ul></li><li><a class="tocitem" href="../WhyActiveInference/">Why Active Inference?</a></li><li><a class="tocitem" href="../">Index</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">General Introduction</a></li><li class="is-active"><a href>Creating the Agent</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Creating the Agent</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/ilabcode/ActiveInference.jl/blob/master/docs/julia_files/AgentCreation.jl#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Creating-the-Agent"><a class="docs-heading-anchor" href="#Creating-the-Agent">Creating the Agent</a><a id="Creating-the-Agent-1"></a><a class="docs-heading-anchor-permalink" href="#Creating-the-Agent" title="Permalink"></a></h1><p>Having created the generative model parameters in the precious section, we&#39;re not ready to intialise an active inference agent. Firstly, we&#39;ll have to specify some settings and hyperparameters that go into the agent struct. We&#39;ll begin with the setting:</p><h3 id="Settings"><a class="docs-heading-anchor" href="#Settings">Settings</a><a id="Settings-1"></a><a class="docs-heading-anchor-permalink" href="#Settings" title="Permalink"></a></h3><p>The settings are a dictionary that contains the following keys:</p><pre><code class="language-julia hljs">settings = Dict(
    &quot;policy_len&quot; =&gt; 1,
    &quot;use_utility&quot; =&gt; true,
    &quot;use_states_info_gain&quot; =&gt; true,
    &quot;use_param_info_gain&quot; =&gt; false,
    &quot;action_selection&quot; =&gt; &quot;stochastic&quot;,
    &quot;modalities_to_learn&quot; =&gt; &quot;all&quot;,
    &quot;factors_to_learn&quot; =&gt; &quot;all&quot;,
    &quot;FPI_num_iter&quot; =&gt; 10,
    &quot;FPI_dF_tol&quot; =&gt; 0.001
)</code></pre><p>The above shown values are the default and will work in most cases. If you&#39;re unsure about what to specify in the settings, you can just use the default values by not specifying them in the settings Dict for the agent. Here, we&#39;ll briefly describe the keys in the settings dictionary:</p><ul><li><strong><code>policy_len</code></strong> - Is the policy length, and as described previously is the number of actions the agent should plan in the future. This is provided as an integer.</li><li><strong><code>use_utility</code></strong> - Is a boolean that specifies whether the agent should use <strong>C</strong> in the expected free energy calculation, that guides the action selection in active inference. If set to <code>false</code>, the agent will not use the parameters specified in <strong>C</strong>.</li><li><strong><code>use_states_info_gain</code></strong> - Is a boolean that specifies whether the agent should use the information gain over states in the expected free energy calculation. If set to <code>false</code>, the agent will not use the information gain over states.</li><li><strong><code>use_param_info_gain</code></strong> - Is a boolean that specifies whether the agent should use the information gain over parameters in the expected free energy calculation. If set to <code>false</code>, the agent will not use the information gain over parameters. Only relevant when learning is included.</li><li><strong><code>action_selection</code></strong> - Is a string that specifies the action selection method. The options are <code>&quot;stochastic&quot;</code> and <code>&quot;deterministic&quot;</code>. If set to <code>&quot;stochastic&quot;</code>, the agent will sample from the posterior over policies, and if set to <code>&quot;deterministic&quot;</code>, the agent will choose the most probable action.</li><li><strong><code>modalities_to_learn</code></strong> - Is a vector of integers that specifies which modalities the agent should learn. If set to string <code>&quot;all&quot;</code>, the agent will learn all modalities. If set to <code>[1,2]</code>, the agent will only learn the first and second modality. Only relevant when learning of A is included.</li><li><strong><code>factors_to_learn</code></strong> - Is a vector of integers that specifies which factors the agent should learn. If set to string <code>&quot;all&quot;</code>, the agent will learn all factors. If set to <code>[1,2]</code>, the agent will only learn the first and second factor. Only relevant when learning of B and D is included.</li><li><strong><code>FPI_num_iter</code></strong> - Is an integer that specifies the number of fixed point iterations (FPI) to perform in the free energy minimization. It can be described as a stop function of the FPI algorithm.</li><li><strong><code>FPI_dF_tol</code></strong> - Is a float that specifies the tolerance of the free energy change in the FPI algorithm over each iteration. If the change in free energy is below this value, the FPI algorithm will also stop.</li></ul><p>For more information on the specifics of the impact of these settings, look under the <code>Active Inference Theory</code> section in the documentation.</p><h3 id="Parameters"><a class="docs-heading-anchor" href="#Parameters">Parameters</a><a id="Parameters-1"></a><a class="docs-heading-anchor-permalink" href="#Parameters" title="Permalink"></a></h3><p>The parameters are a dictionary that contains the following keys:</p><pre><code class="language-julia hljs">parameters = Dict(
&quot;gamma&quot; =&gt; 16.0,
&quot;alpha&quot; =&gt; 16.0,
&quot;lr_pA&quot; =&gt; 1.0,
&quot;fr_pA&quot; =&gt; 1.0,
&quot;lr_pB&quot; =&gt; 1.0,
&quot;fr_pB&quot; =&gt; 1.0,
&quot;lr_pD&quot; =&gt; 1.0,
&quot;fr_pD&quot; =&gt; 1.0
)</code></pre><p>The above shown values are the default. If you&#39;re unsure about what to specify in the parameters, you can just use the default values by not specifying them in the parameter Dict for the agent. Here, we&#39;ll briefly describe the keys in the parameters dictionary containing the hyperparameters:</p><ul><li><strong><code>alpha</code></strong> - Is the inverse temperature of the action selection process, and usually takes a value between 1 and 32. This is only relevant when action_selection is set to <code>&quot;stochastic&quot;</code>.</li><li><strong><code>gamma</code></strong> - Is the inverse temperature precision of the expected free energy, and usually takes a value between 1 and 32. If the value is high, the agent will be more certain in its beliefs regarding the posterior probability over policies.</li><li><strong><code>lr_pA</code></strong> - Is the learning rate of <strong>A</strong>, and usually takes a value between 0 and 1. Only relevant when learning is included, and this goes for all learning and forgetting rates.</li><li><strong><code>fr_pA</code></strong> - Is the forgetting rate of <strong>A</strong>, and usually takes a value between 0 and 1. If forgetting rate is 1 it means no forgetting.</li><li><strong><code>lr_pB</code></strong> - Is the learning rate of <strong>B</strong>, and usually takes a value between 0 and 1.</li><li><strong><code>fr_pB</code></strong> - Is the forgetting rate of <strong>B</strong>, and usually takes a value between 0 and 1. If forgetting rate is 1 it means no forgetting.</li><li><strong><code>lr_pD</code></strong> - Is the learning rate of <strong>D</strong>, and usually takes a value between 0 and 1.</li><li><strong><code>fr_pD</code></strong> - Is the forgetting rate of <strong>D</strong>, and usually takes a value between 0 and 1. If forgetting rate is 1 it means no forgetting.</li></ul><p>Having now specified the setting and parameters, we can now initialise the active inference agent. This is done by calling the <code>init_aif</code> function, which takes the following arguments:</p><h2 id="Initilising-the-Agent"><a class="docs-heading-anchor" href="#Initilising-the-Agent">Initilising the Agent</a><a id="Initilising-the-Agent-1"></a><a class="docs-heading-anchor-permalink" href="#Initilising-the-Agent" title="Permalink"></a></h2><pre><code class="language-julia hljs">aif_agent = init_aif(
    A, B, C = C, D = D, E = E, settings = settings, parameters = parameters, verbose = false
);</code></pre><p>You can access the settings and parameters of the agent by calling the agent struct on the agent:</p><pre><code class="language-julia hljs">aif_agent.parameters</code></pre><pre><code class="nohighlight hljs">Dict{String, Real} with 8 entries:
  &quot;lr_pA&quot; =&gt; 1.0
  &quot;fr_pA&quot; =&gt; 1.0
  &quot;lr_pB&quot; =&gt; 1.0
  &quot;lr_pD&quot; =&gt; 1.0
  &quot;alpha&quot; =&gt; 16.0
  &quot;gamma&quot; =&gt; 16.0
  &quot;fr_pB&quot; =&gt; 1.0
  &quot;fr_pD&quot; =&gt; 1.0</code></pre><pre><code class="language-julia hljs">aif_agent.settings</code></pre><pre><code class="nohighlight hljs">Dict{String, Any} with 11 entries:
  &quot;policy_len&quot; =&gt; 1
  &quot;FPI_dF_tol&quot; =&gt; 0.001
  &quot;control_fac_idx&quot; =&gt; [1]
  &quot;action_selection&quot; =&gt; &quot;stochastic&quot;
  &quot;num_controls&quot; =&gt; [4, 1]
  &quot;FPI_num_iter&quot; =&gt; 10
  &quot;modalities_to_learn&quot; =&gt; &quot;all&quot;
  &quot;use_utility&quot; =&gt; true
  &quot;factors_to_learn&quot; =&gt; &quot;all&quot;
  &quot;use_param_info_gain&quot; =&gt; false
  &quot;use_states_info_gain&quot; =&gt; true</code></pre><p>Having now initialised the agent, we are ready to implement it either in a simulation with a perception-action loop, or for use in model fitting with observed data.</p><h2 id="Initialising-the-Agent-with-Learning"><a class="docs-heading-anchor" href="#Initialising-the-Agent-with-Learning">Initialising the Agent with Learning</a><a id="Initialising-the-Agent-with-Learning-1"></a><a class="docs-heading-anchor-permalink" href="#Initialising-the-Agent-with-Learning" title="Permalink"></a></h2><p>If you want to include learning in the agent, you can do so by specifying the prior parameters <code>init_aif</code> function. Here is an example of how to initialise the agent with learning:</p><pre><code class="language-julia hljs">aif_agent = init_aif(
    A, B, C = C, D = D, E = E, pA = pA, pB = pB, pD = pD, settings = settings, parameters = parameters, verbose = false
);</code></pre><p>Here, only the prior of the parameters that are to be learned should be specified.</p><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../GenerativeModelCreation/">« Creation of the Generative Model</a><a class="docs-footer-nextpage" href="../Simulation/">Simulation »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Wednesday 27 November 2024 15:11">Wednesday 27 November 2024</span>. Using Julia version 1.11.1.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
